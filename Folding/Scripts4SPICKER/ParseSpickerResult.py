import os
import sys
import numpy as np
import json
import shutil
import subprocess
import tempfile

#this script parses the clustering result generated by spicker
#two result files needed: rst.dat, str.txt
#one mapping file needed: mapping.json. This file mapping decoy numbering used in clustering to its real file name
#one model list file needed: models4clustering.list

def Usage():
	print 'python ParseSpickerResult.py targetName folder4ClusterResults [savefolder]'
	print '	This script parses the clustering result generated by Spicker'
	print '	folder4ClusterResults: the folder for clustering results'
	print '	savefolder: the folder for result saving, default the same folder as above'

def is_tool(name):
    try:
        devnull = open(os.devnull)
        subprocess.Popen([name], stdout=devnull, stderr=devnull).communicate()
    except OSError as e:
        if e.errno == os.errno.ENOENT:
            return False
    return True

## run maxcluster64bit to find the original model file which has the same Ca-trace for CaFile
def FindModelFile(CaFile, modelListFile):
	tmpfh, tmpfilename= tempfile.mkstemp()

	cmdStr = 'maxcluster64bit -rmsd -l ' + modelListFile + ' -e ' + CaFile + ' > ' + tmpfilename
	os.system(cmdStr)

	with open(tmpfilename, 'r') as fh:
		content=[ line.strip() for line in list(fh) ]

	fields = content[-1].split()
	if len(fields) < 14:
		print 'ERROR: unexpected content in the output of maxcluster64but for ', CaFile, 'and', modelListFile
		print 'ERROR:	', content[-1]
		exit(1)
	modelfile = fields[5]
	rmsd = np.float32(fields[7])
	if rmsd > 0.1:
		print 'WARNING: the detected modelfile has RMSD >0.1 with the targeted Ca file : ', modelfile
		exit(1)

	os.remove(tmpfilename)

	return modelfile

	
if len(sys.argv) < 3: 
	Usage()
	exit(1)

targetName = sys.argv[1]
folder4clustering = os.path.abspath(sys.argv[2])
savefolder = folder4clustering
if len(sys.argv)>= 4:
	savefolder = sys.argv[3]
	os.mkdir(savefolder)

rstdat = os.path.join(folder4clustering, 'rst.dat')
strtxt = os.path.join(folder4clustering, 'str.txt')
modelListFile = os.path.join(folder4clustering, 'models4clustering.list')

if not os.path.isfile(modelListFile):
	print 'ERROR: cannot find the model list file: ', modelListFile
	exit(1)

## parse rstdat, and find the position with Rc_in
with open(rstdat, 'r') as fh:
	content = [ line.strip() for line in list(fh) ]

numClusters = 0
for row, i in zip(content, range(len(content)) ):
	if "Number of clusters:" in row:
		fields = row.split(':')
		numClusters = np.int32(fields[1])
		break

if numClusters <= 0:
	print 'ERROR: 0 clusters detected in ', rstdat
	exit(1)

content = content[i+1: ]
for row, i in zip(content, range(len(content)) ):
        if "include used structure" in row:
                break

content = content[i+4: ]

clusters = []
# get cluster size, Rc_in
for i in range(numClusters):
	fields = content[i].split()
	if len(fields) != 7:
                print 'ERROR: incorrect format in rstdat line: ', content[i], rstdat
                exit(1)
	clusterNo = np.int32(fields[0])
	clusterSize = np.int32(fields[1])
	Rc_in = np.float32(fields[3])
	if clusterSize <= 1:
		clusterDensity = 0
	else:
		clusterDensity = clusterSize / Rc_in
	clusters.append( (clusterNo, clusterDensity, clusterSize, Rc_in) )

## sort by density from high to low
clusters_sorted = sorted(clusters, reverse=True, key=lambda x: x[1])
clusters = clusters_sorted

## find the original model file for closc1, closc2, ...
if not is_tool('maxcluster64bit'):
	print 'ERROR: failed to find maxcluster64bit. Please install it or set PATH to this program'
	exit(1)

outStrs = []
for c, i  in zip(clusters, range(len(clusters)) ):
	clusterNo = c[0]
	CaFile = os.path.join(folder4clustering, 'closc' + str(clusterNo) + '.pdb')
	modelfile = FindModelFile(CaFile, modelListFile)
	shutil.copyfile(modelfile, os.path.join(savefolder, targetName + '_center' + str(i) + '.pdb') )

	outStr = '\t'.join( [str(i), modelfile] +  [str(e) for e in c] )
	outStrs.append(outStr)

savefile = os.path.join(savefolder, 'ClusteringSummary.txt')
with open(savefile, 'w') as fh:
	fh.writelines('\n'.join(outStrs) )
