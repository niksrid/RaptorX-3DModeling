import os
import sys
import numpy as np
import tempfile
import random
import string
from subprocess import call

##this script evaluates per-atom errors of one 3D model by comparing it to a list of reference decoys.
## please make sure that the program DeepScore can be found by command "which DeepScore"
DeepScoreProgram="DeepScore"

## test if a program exists or not
def is_tool(name):
    try:
        devnull = open(os.devnull)
        subprocess.Popen([name], stdout=devnull, stderr=devnull).communicate()
    except OSError as e:
        if e.errno == os.errno.ENOENT:
            return False
    return True

def Usage():
	print 'python EstimateError.py [-o resultfile] targetModel refModelList1 refModelList2 refModelList3 ...'
	print '	This script estimates the global and per-atom quality of a target model by comparing it to a few lists of reference models'
	print '	targetModel: a 3D model file (in PDB format) for quality assessment'
	print '	refModelList: a file contains a list of reference models, each in one row. Multiple files can be used.'
	print '	    Each row in refModelList contains a reference model file name and optionally its confidence score.'
	print '	resultfile: the file for quality saving. It is better to provide a file to avoid overwriting.'
	print '	    By default, the result file is named after QualityScore-modelName.txt where modelName is the basename of targetModel.'
	print '	    In a resultfile, the first two rows are global quality and the others are per-atom local quality'
	print '	    Each row has 6 columns: residue, atom, ase, TMscore, GDT and RMSD' 
	print '	    To get Ca local quality assessment, use grep -v REMARK resultfile | grep -w CA'

def Distance2GDT( d ):
	gdt = 0.
	if d<=8:
		gdt += 1.
	if d<=4:
		gdt += 1.
	if d<=2:
		gdt += 1.
	if d<=1:
		gdt += 1.

	return gdt/4.	

def Distance2ASE(d):
	return 1/(1+ d*d/25.)

def ASE2Distance( ase ):
	return np.sqrt( 25 * (1/ase -1.) )

def Compare2Models(targetModel, refModel):

	detailFile = 'DeepScore.' + str(os.getpid()) + '.' + ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(10))
	
	## call DeepScore to generate detailed comparison of two models, using the targetModel length as normalization length
	cmd = ["DeepScore", targetModel, refModel, "-D", detailFile, "-n", "-1"]
	#print cmd
	call(cmd)
	with open(detailFile, 'r') as fh:
		content = [ line.strip() for line in list(fh) ]
	os.remove(detailFile)

	distances_sqr = []
	tmscores = []
	gdts= []
	ases = []

	atoms = []
	for row in content:
		fields = row.split()
		if len(fields) != 8:
			print "ERROR: incorrect format in the detailed result file generated by DeepScore. Each line shall have 8 columns and the last 2 are distance and TMscore, respectively."
			exit(1)

		distance = np.float32(fields[6])
		tmscore = np.float32(fields[7])
		distances_sqr.append(distance*distance)
		tmscores.append(tmscore)

		## convert distance to ASE
		ases.append(Distance2ASE(distance) )

		## convert distance to gdt
		gdts.append(Distance2GDT(distance) )

		atoms.append( (fields[0], fields[1]) )

	return atoms, distances_sqr, tmscores, ases, gdts

## this function compares one targetModel to a list of reference models
def CompareWithModelSet(targetModel, refModels):
	results = []
	weights = []
	numRefModels = len(refModels)

	for refModel, w in refModels:
		## we do not compare the targetModel to itself
		if os.path.realpath(targetModel) == os.path.realpath(refModel):
			numRefModels = numRefModels - 1
			continue

		atoms, distances_sqr, tmscores, ases, gdts = Compare2Models(targetModel, refModel)
		results.append(np.array([distances_sqr, gdts, tmscores, ases]) )
		weights.append(w)

	## add code here to check if all the comparison results have the same set of atoms

	## add code here to summarize
	return np.average(results, axis=0, weights=weights), numRefModels, atoms

import getopt

def main(argv):

	try:
                opts, args = getopt.getopt(argv,"o:",["output="])
                #print opts, args
        except getopt.GetoptError:
                Usage()
                exit(1)

	if len(args)<2:
		Usage()
		exit(1)

	targetModel = args[0]
	refLists = args[1:] 

	savefile = "QualityScore-" + os.path.basename(targetModel ) + ".txt"
	for opt, arg in opts:
                if opt in ("-o", "--output"):
			savefile=arg
		else:
			Usage()
			exit(1)

	print "targetModel=", targetModel
	print "ref models =", refLists
	print "savefile=", savefile

	results = []
	CaTMscore = []

	## the number of models in each refList file
	numModelsOfAllLists = []

	finalAtoms = None

	for reflist in refLists:
		with open(reflist, 'r') as fh:
			refModels = [ line.strip() for line in list(fh) ]
		if not refModels:
			print 'WARNING: no reference models found in file:', reflist
			continue

		## deal with model weight here
		refModels2 = []
		for ref in refModels:
			fields = ref.split()
			modelFile = fields[0]
			modelWeight = 1.
			if len(fields)>=2:
				modelWeight = np.float32(fields[1])

			refModels2.append( (modelFile, modelWeight) )
		
		res, numModels, atoms = CompareWithModelSet(targetModel, refModels2 )	
		results.append(res)
		numModelsOfAllLists.append(numModels)

		## add code to check consistency of atoms
		
		finalAtoms = atoms

	avgResult = np.average(results, axis=0, weights=numModelsOfAllLists)

	estimatedASE = avgResult[-1] 
	estimatedTM = avgResult[-2]
	estimatedGDT = avgResult[-3]

	ASE = np.average(estimatedASE)
	GDT = np.average(estimatedGDT)
	TM = np.average(estimatedTM)

	## convert ASE back to distance
	estimatedDistance = [ ASE2Distance(ase) for ase in estimatedASE ]
	RMSD = np.sqrt( np.average( np.square(estimatedDistance) ) )

	CaASEs = [ ase for a, ase in zip(finalAtoms, estimatedASE) if a[1]=='CA' ]
	CaGDTs = [ gdt for a, gdt in zip(finalAtoms, estimatedGDT) if a[1]=='CA' ]
	CaTMs = [ tm for a, tm in zip(finalAtoms, estimatedTM) if a[1]=='CA' ]
	CaDistances = [ d for a, d in zip(finalAtoms, estimatedDistance) if a[1]=='CA' ]

	CaASE = np.average(CaASEs)
	CaGDT = np.average(CaGDTs)
	CaTM = np.average(CaTMs)
	CaRMSD = np.sqrt( np.average( np.square(CaDistances) ) )

	with open(savefile, 'w') as fh:
		fh.write('REMARK all-atom ASE, TMscore, GDT, RMSD: ')
		fh.write(str([ASE, TM, GDT, RMSD]) + '\n')

		fh.write('REMARK Ca ASE, TMscore, GDT, RMSD: ')
		fh.write(str([CaASE, CaTM, CaGDT, CaRMSD]) + '\n')
	
		for a, ase, tm, gdt, d in zip(finalAtoms, estimatedASE, estimatedTM, estimatedGDT, estimatedDistance):
			fh.write("%s\t%s\t%.4f\t%.4f\t%.4f\t%.2f\n" % (a[0], a[1], ase, tm, gdt, d) )

if __name__ == "__main__":
        main(sys.argv[1:])
